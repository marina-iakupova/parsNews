# -*- coding: utf-8 -*-
"""
Created on Mon Jun 27 19:58:17 2016

@author: Марина
"""

# coding: utf8
import urllib.request
from bs4 import BeautifulSoup
import re
import string
import bs4
import codecs
import pymorphy2

morph = pymorphy2.MorphAnalyzer()

class workWithLinks:
	mainlinks='http://lentachel.ru/sections/transport'
	withNumPage=250
	numPage=0
	
	def getLinksPage (mainlinks):
		while withNumPage<=5000:
			link=[]
			f = urllib.request.urlopen(mainlinks)
			mainlinks='http://lentachel.ru/sections/transport/%s'%withNumPage
			withNumPage=withNumPage+50
			link+=[mainlinks]
		return link

	def getLinksOnPage(link, numPage):
		g = urllib.request.urlopen(link[numPage])
		links = BeautifulSoup(g)
		for links in links.find_all('a'):
			newlinks=links.get('href')
		return newlinks
  
	def filtrLinks(newlinks):
		pattern='http://lentachel.ru/articles/\d\d\d\d\d'
		alllinks =re.findall(pattern, newlinks)
		return alllinks

class workWithFiles:
	nameFileNews=1

	def openFile(path, mode):
		return codecs.open(path, mode, 'utf-8')
	

class workWithText:
	def getText(alllinks):
		f = urllib.request.urlopen(alllinks)
		content = BeautifulSoup(f)
		date=content.find('div', 'date')
		date=date.get_text()
		return date
	
class redactText:
		work_file='alltext.txt'

		def openFile(work_file):
			file = open(work_file,'r', encoding='utf-8')
			try:
				txt = file.read()
				return txt       
			finally:
				file.close()
			

		def getDate(text):
			regDate=re.compile(r'/([0-2]\d|3[01])\.(0\d|1[012])\.(\d{4})/')
			date = re.search(regDate, text)
			date=date.group()
			if date:
				return date
			else:
				print 'No match'

		def getTime(text):
			regDate=re.compile(r'^(\d\d:\d\d:\d\d(;|$)){4}(?<!;)$')
			date = re.search(regDate, text)
			date=date.group()
			if date:
				return date
			else:
				print 'No match'
				
		def getWordFromText(text):
			p = re.compile("([a-zA-Z-а-яА-Я']+)")
			res=p.findall(text)
			return res
	

	
	
workWithLinks=wwl()
workWithFiles=wwf()
workWithText=wwt()
	
link+=wwl.getLinksPage(mainlinks)
while numPage<=95:
	newlinks=wwl.getLinksOnPage(link, numPage)
	numPage=numPage+1
	alllinks=wwl.filtrLinks(newlinks)
	
    for alllinks in alllinks:
            date=wwt.getText(alllinks)
            f1 = open("all.txt", 'a')
            f1.write(date)
            f1.write(' ')
            f1.write(alllinks)
            f1.write('\r\n')
            f1.close
            for content in content.find('div', 'text'):
                  textall2= content.find('p')
                  if textall2!=-1:
                      text=textall2
                      text=text.get_text()
                      f = wwf.openFile("C:/Python33/textmin/news/%s.txt"%nameFileNews, 'a')
                      nameFileNews=nameFileNews+1
                      f.write(date)
                      f.write('\r\n')
                      f.write(text)
                      f2= wwf.openFile("alltext.txt", 'a')
                      f2.write(text)
                      f2.write(' ')
                      f1.close
                      f2.close


redactText=rt()

txt=rt.openFile(work_file)

date=rt.getDate(txt)
print (date)

time=rt.getTime(txt)
print (time)

res=rt.getWordFromText(txt)
print (res)
